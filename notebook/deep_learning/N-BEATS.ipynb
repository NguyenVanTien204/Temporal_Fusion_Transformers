{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gDBZOV3y5JZK","executionInfo":{"status":"ok","timestamp":1764930572883,"user_tz":-420,"elapsed":2177,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}},"outputId":"8baec529-7240-4ff4-db89-b36e4a2ecbde"},"id":"gDBZOV3y5JZK","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":14,"id":"aac2eb03","metadata":{"id":"aac2eb03","executionInfo":{"status":"ok","timestamp":1764930572907,"user_tz":-420,"elapsed":13,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from pathlib import Path\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","SEED = 42\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","DATA_DIR = Path(\"/content/drive/MyDrive/ParquetFile\")\n","RESULTS_DIR = Path(\"/content/drive/MyDrive/ParquetFile\")\n","MODEL_DIR = Path(\"/content/drive/MyDrive/ParquetFile\")\n","for path in [RESULTS_DIR, MODEL_DIR]:\n","    path.mkdir(parents=True, exist_ok=True)\n","\n","VAL_WEEKS = 6\n","SEQ_LEN = 30\n","BATCH_SIZE = 512\n","EPOCHS = 40\n","LR = 1e-3\n","PATIENCE = 7\n","HIDDEN_UNITS = 256\n","NUM_BLOCKS = 4\n","NUM_LAYERS_PER_BLOCK = 4\n","FORECAST_LENGTH = 1\n","DROPOUT = 0.1\n","MODEL_PATH = MODEL_DIR / \"nbeats_best.pt\""]},{"cell_type":"code","execution_count":15,"id":"3f1e8155","metadata":{"id":"3f1e8155","executionInfo":{"status":"ok","timestamp":1764930573630,"user_tz":-420,"elapsed":734,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"705aaae0-2f7a-4a63-da74-abf5aea6c929"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train raw shape: (830972, 28)\n","Test raw shape : (1113, 26)\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 830972 entries, 0 to 830971\n","Data columns (total 28 columns):\n"," #   Column                   Non-Null Count   Dtype  \n","---  ------                   --------------   -----  \n"," 0   Store                    830972 non-null  int64  \n"," 1   DayOfWeek                830972 non-null  int32  \n"," 2   Sales                    830972 non-null  float64\n"," 3   Customers                830972 non-null  int64  \n"," 4   Open                     830972 non-null  int64  \n"," 5   Promo                    830972 non-null  int64  \n"," 6   StateHoliday             830972 non-null  object \n"," 7   SchoolHoliday            830972 non-null  int64  \n"," 8   StoreType                830972 non-null  object \n"," 9   Assortment               830972 non-null  object \n"," 10  CompetitionDistance      830972 non-null  float64\n"," 11  Promo2                   830972 non-null  int64  \n"," 12  CompetitionMissingFlag   830972 non-null  int64  \n"," 13  LogSales                 830972 non-null  float64\n"," 14  Year                     830972 non-null  int32  \n"," 15  Month                    830972 non-null  int32  \n"," 16  Day                      830972 non-null  int32  \n"," 17  WeekOfYear               830972 non-null  int64  \n"," 18  IsWeekend                830972 non-null  int64  \n"," 19  IsMonthStart             830972 non-null  int64  \n"," 20  IsMonthEnd               830972 non-null  int64  \n"," 21  CompetitionMonthsActive  566625 non-null  float64\n"," 22  Promo2WeeksActive        414227 non-null  float64\n"," 23  PromoIntervalActive      830972 non-null  int64  \n"," 24  Lag_1                    830954 non-null  float64\n"," 25  Lag_7                    825394 non-null  float64\n"," 26  Rolling_Mean_7           825394 non-null  float64\n"," 27  Rolling_Std_7            825394 non-null  float64\n","dtypes: float64(9), int32(4), int64(12), object(3)\n","memory usage: 164.8+ MB\n"]}],"source":["train_raw = pd.read_parquet(DATA_DIR / \"train_fe.parquet\").copy()\n","test_raw = pd.read_parquet(DATA_DIR / \"test_fe.parquet\").copy()\n","\n","print(f\"Train raw shape: {train_raw.shape}\")\n","print(f\"Test raw shape : {test_raw.shape}\")\n","\n","train_raw.info()"]},{"cell_type":"code","execution_count":16,"id":"341810e9","metadata":{"id":"341810e9","executionInfo":{"status":"ok","timestamp":1764930575365,"user_tz":-420,"elapsed":1723,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c1766080-510f-4fff-9565-84130749a40a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape (post-encoding): (830972, 34)\n","Test shape  (post-encoding): (1113, 34)\n","Feature count: 30\n"]}],"source":["TARGET_COL = \"Sales\"\n","ID_COL = \"Store\"\n","DATE_PARTS = [\"Year\", \"Month\", \"Day\"]\n","CAT_COLS = [\"StateHoliday\", \"StoreType\", \"Assortment\"]\n","LEAK_COLS = {TARGET_COL, \"Customers\", \"LogSales\", \"Date\"}\n","NA_ZERO_COLS = [\n","    \"CompetitionMonthsActive\",\n","    \"Promo2WeeksActive\",\n","    \"Lag_1\",\n","    \"Lag_7\",\n","    \"Rolling_Mean_7\",\n","    \"Rolling_Std_7\",\n","]\n","\n","OPTIONAL_TEST_COLS = [TARGET_COL, \"Customers\", \"LogSales\"]\n","for col in OPTIONAL_TEST_COLS:\n","    if col not in test_raw.columns:\n","        test_raw[col] = np.nan\n","\n","df_train = train_raw.copy()\n","df_test = test_raw.copy()\n","\n","for frame in [df_train, df_test]:\n","    date_frame = frame[DATE_PARTS].rename(columns={\"Year\": \"year\", \"Month\": \"month\", \"Day\": \"day\"})\n","    frame[\"Date\"] = pd.to_datetime(date_frame)\n","    frame.sort_values([ID_COL, \"Date\"], inplace=True)\n","    frame.reset_index(drop=True, inplace=True)\n","\n","df_train[\"dataset\"] = \"train\"\n","df_test[\"dataset\"] = \"test\"\n","combined = pd.concat([df_train, df_test], ignore_index=True)\n","\n","for col in CAT_COLS:\n","    if col in combined.columns:\n","        combined[col] = combined[col].astype(str)\n","\n","for col in NA_ZERO_COLS:\n","    if col in combined.columns:\n","        combined[col] = combined[col].fillna(0)\n","\n","combined = pd.get_dummies(combined, columns=CAT_COLS, drop_first=True)\n","combined = combined.sort_values([ID_COL, \"Date\"]).reset_index(drop=True)\n","\n","df_train = combined[combined[\"dataset\"] == \"train\"].drop(columns=[\"dataset\"]).reset_index(drop=True)\n","df_test = combined[combined[\"dataset\"] == \"test\"].drop(columns=[\"dataset\"]).reset_index(drop=True)\n","\n","FEATURE_COLS = [col for col in df_train.columns if col not in LEAK_COLS]\n","\n","print(f\"Train shape (post-encoding): {df_train.shape}\")\n","print(f\"Test shape  (post-encoding): {df_test.shape}\")\n","print(f\"Feature count: {len(FEATURE_COLS)}\")"]},{"cell_type":"code","source":["print(FEATURE_COLS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TmrHW-ZIBLSD","executionInfo":{"status":"ok","timestamp":1764931040643,"user_tz":-420,"elapsed":20,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}},"outputId":"58c8eae1-594b-48a3-f8a3-b4121ed08ae0"},"id":"TmrHW-ZIBLSD","execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["['Store', 'DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', 'CompetitionDistance', 'Promo2', 'CompetitionMissingFlag', 'Year', 'Month', 'Day', 'WeekOfYear', 'IsWeekend', 'IsMonthStart', 'IsMonthEnd', 'CompetitionMonthsActive', 'Promo2WeeksActive', 'PromoIntervalActive', 'Lag_1', 'Lag_7', 'Rolling_Mean_7', 'Rolling_Std_7', 'StateHoliday_a', 'StateHoliday_b', 'StateHoliday_c', 'StoreType_b', 'StoreType_c', 'StoreType_d', 'Assortment_b', 'Assortment_c']\n"]}]},{"cell_type":"code","execution_count":18,"id":"4bf7c07b","metadata":{"id":"4bf7c07b","executionInfo":{"status":"ok","timestamp":1764930576813,"user_tz":-420,"elapsed":1427,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"21342d66-c154-40df-e3e4-f44807eaab73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Split date: 2015-06-05\n","Train rows: 789,557 | Val rows: 41,415\n"]}],"source":["split_date = df_train[\"Date\"].max() - pd.Timedelta(weeks=VAL_WEEKS)\n","\n","train_main = df_train[df_train[\"Date\"] < split_date].copy()\n","val_main = df_train[df_train[\"Date\"] >= split_date].copy()\n","\n","feature_scaler = StandardScaler()\n","target_scaler = StandardScaler()\n","\n","train_main[FEATURE_COLS] = feature_scaler.fit_transform(train_main[FEATURE_COLS])\n","val_main[FEATURE_COLS] = feature_scaler.transform(val_main[FEATURE_COLS])\n","\n","test_scaled = df_test.copy()\n","test_scaled[FEATURE_COLS] = feature_scaler.transform(test_scaled[FEATURE_COLS])\n","\n","train_main[[TARGET_COL]] = target_scaler.fit_transform(train_main[[TARGET_COL]])\n","val_main[[TARGET_COL]] = target_scaler.transform(val_main[[TARGET_COL]])\n","\n","print(f\"Split date: {split_date.date()}\")\n","print(f\"Train rows: {len(train_main):,} | Val rows: {len(val_main):,}\")"]},{"cell_type":"code","execution_count":19,"id":"5655486e","metadata":{"id":"5655486e","executionInfo":{"status":"ok","timestamp":1764930583006,"user_tz":-420,"elapsed":6196,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c697dfd0-d8c3-4947-88c0-59596165acec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train sequences: (756107, 30, 30)\n","Val sequences  : (7977, 30, 30)\n"]}],"source":["def build_sequences(df: pd.DataFrame, feature_cols: list, target_col: str):\n","    sequences, targets = [], []\n","    for _, group in df.groupby(ID_COL):\n","        group = group.sort_values(\"Date\")\n","        feature_values = group[feature_cols].to_numpy(dtype=np.float32)\n","        target_values = group[target_col].to_numpy(dtype=np.float32)\n","        if len(feature_values) <= SEQ_LEN:\n","            continue\n","        for start in range(len(feature_values) - SEQ_LEN):\n","            end = start + SEQ_LEN\n","            sequences.append(feature_values[start:end])\n","            targets.append(target_values[end])\n","    return np.array(sequences), np.array(targets)\n","\n","X_train, y_train = build_sequences(train_main, FEATURE_COLS, TARGET_COL)\n","X_val, y_val = build_sequences(val_main, FEATURE_COLS, TARGET_COL)\n","\n","print(f\"Train sequences: {X_train.shape}\")\n","print(f\"Val sequences  : {X_val.shape}\")"]},{"cell_type":"code","execution_count":20,"id":"9ae41eaa","metadata":{"id":"9ae41eaa","executionInfo":{"status":"ok","timestamp":1764930584455,"user_tz":-420,"elapsed":1448,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"239df8f4-abf0-46af-9542-f7478f7f1138"},"outputs":[{"output_type":"stream","name":"stdout","text":["Batches -> train: 1477, val: 16\n"]}],"source":["class SequenceDataset(Dataset):\n","    def __init__(self, X, y=None):\n","        self.X = torch.tensor(X, dtype=torch.float32)\n","        self.y = None if y is None else torch.tensor(y, dtype=torch.float32)\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        if self.y is None:\n","            return self.X[idx]\n","        return self.X[idx], self.y[idx]\n","\n","train_ds = SequenceDataset(X_train, y_train)\n","val_ds = SequenceDataset(X_val, y_val)\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n","val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n","\n","print(f\"Batches -> train: {len(train_loader)}, val: {len(val_loader)}\")"]},{"cell_type":"code","execution_count":21,"id":"749f8434","metadata":{"id":"749f8434","executionInfo":{"status":"ok","timestamp":1764930584501,"user_tz":-420,"elapsed":17,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"40a8bc9d-faaa-4043-b824-9702ce32b7c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["NBeats(\n","  (blocks): ModuleList(\n","    (0-3): 4 x NBeatsBlock(\n","      (fc_layers): ModuleList(\n","        (0): Linear(in_features=900, out_features=256, bias=True)\n","        (1-3): 3 x Linear(in_features=256, out_features=256, bias=True)\n","      )\n","      (activation): ReLU()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","      (theta_layer): Linear(in_features=256, out_features=901, bias=True)\n","    )\n","  )\n",")\n","Trainable parameters: 2,638,356\n"]}],"source":["class NBeatsBlock(nn.Module):\n","    def __init__(self, input_dim: int, theta_dim: int, hidden_units: int, num_layers: int, dropout: float):\n","        super().__init__()\n","        layers = []\n","        last_dim = input_dim\n","        for _ in range(num_layers):\n","            layers.append(nn.Linear(last_dim, hidden_units))\n","            last_dim = hidden_units\n","        self.fc_layers = nn.ModuleList(layers)\n","        self.activation = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","        self.theta_layer = nn.Linear(hidden_units, theta_dim)\n","        self.backcast_dim = input_dim\n","        self.forecast_dim = theta_dim - input_dim\n","\n","    def forward(self, x):\n","        out = x\n","        for layer in self.fc_layers:\n","            out = self.activation(layer(out))\n","            out = self.dropout(out)\n","        theta = self.theta_layer(out)\n","        backcast = theta[:, : self.backcast_dim]\n","        forecast = theta[:, self.backcast_dim :]\n","        return backcast, forecast\n","\n","\n","class NBeats(nn.Module):\n","    def __init__(\n","        self,\n","        seq_len: int,\n","        num_features: int,\n","        forecast_length: int,\n","        hidden_units: int,\n","        num_blocks: int,\n","        num_layers: int,\n","        dropout: float,\n","    ):\n","        super().__init__()\n","        self.backcast_dim = seq_len * num_features\n","        self.forecast_dim = forecast_length\n","        theta_dim = self.backcast_dim + self.forecast_dim\n","        self.blocks = nn.ModuleList(\n","            [\n","                NBeatsBlock(\n","                    input_dim=self.backcast_dim,\n","                    theta_dim=theta_dim,\n","                    hidden_units=hidden_units,\n","                    num_layers=num_layers,\n","                    dropout=dropout,\n","                )\n","                for _ in range(num_blocks)\n","            ]\n","        )\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        residual = x.reshape(batch_size, -1)\n","        forecast = torch.zeros((batch_size, self.forecast_dim), device=x.device)\n","        for block in self.blocks:\n","            backcast, block_forecast = block(residual)\n","            residual = residual - backcast\n","            forecast = forecast + block_forecast\n","        return forecast.squeeze(-1)\n","\n","\n","model = NBeats(\n","    seq_len=SEQ_LEN,\n","    num_features=len(FEATURE_COLS),\n","    forecast_length=FORECAST_LENGTH,\n","    hidden_units=HIDDEN_UNITS,\n","    num_blocks=NUM_BLOCKS,\n","    num_layers=NUM_LAYERS_PER_BLOCK,\n","    dropout=DROPOUT,\n",").to(DEVICE)\n","\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(model)\n","print(f\"Trainable parameters: {trainable_params:,}\")"]},{"cell_type":"code","execution_count":22,"id":"194ecb2b","metadata":{"id":"194ecb2b","executionInfo":{"status":"ok","timestamp":1764930756006,"user_tz":-420,"elapsed":171504,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"090b9960-95e6-4dcc-a1e0-e96c69e5980e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 01 | Train MSE 0.1013 | Train MAE 0.2151 | Val MSE 0.0833 | Val MAE 0.2169\n","Epoch 02 | Train MSE 0.0705 | Train MAE 0.1812 | Val MSE 0.0741 | Val MAE 0.2051\n","Epoch 03 | Train MSE 0.0650 | Train MAE 0.1738 | Val MSE 0.0913 | Val MAE 0.2235\n","Epoch 04 | Train MSE 0.0617 | Train MAE 0.1693 | Val MSE 0.1008 | Val MAE 0.2291\n","Epoch 05 | Train MSE 0.0595 | Train MAE 0.1666 | Val MSE 0.0861 | Val MAE 0.2156\n","Epoch 06 | Train MSE 0.0523 | Train MAE 0.1564 | Val MSE 0.0827 | Val MAE 0.2124\n","Epoch 07 | Train MSE 0.0505 | Train MAE 0.1543 | Val MSE 0.0801 | Val MAE 0.2117\n","Epoch 08 | Train MSE 0.0493 | Train MAE 0.1529 | Val MSE 0.0786 | Val MAE 0.2066\n","Epoch 09 | Train MSE 0.0459 | Train MAE 0.1479 | Val MSE 0.0849 | Val MAE 0.2127\n","Early stopping triggered.\n"]}],"source":["criterion = nn.MSELoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.5, patience=2\n",")\n","\n","\n","def run_epoch(loader, train_mode: bool):\n","    epoch_loss, epoch_mae, steps = 0.0, 0.0, 0\n","    model.train(mode=train_mode)\n","    context = torch.enable_grad() if train_mode else torch.no_grad()\n","    with context:\n","        for batch in loader:\n","            features, targets = [tensor.to(DEVICE) for tensor in batch]\n","            if train_mode:\n","                optimizer.zero_grad()\n","            preds = model(features)\n","            loss = criterion(preds, targets)\n","            mae = torch.mean(torch.abs(preds - targets))\n","            if train_mode:\n","                loss.backward()\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n","                optimizer.step()\n","            epoch_loss += loss.item()\n","            epoch_mae += mae.item()\n","            steps += 1\n","    return epoch_loss / steps, epoch_mae / steps\n","\n","\n","history = []\n","best_loss = float(\"inf\")\n","patience_counter = 0\n","\n","for epoch in range(1, EPOCHS + 1):\n","    train_loss, train_mae = run_epoch(train_loader, train_mode=True)\n","    val_loss, val_mae = run_epoch(val_loader, train_mode=False)\n","    scheduler.step(val_loss)\n","\n","    history.append(\n","        {\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss, \"val_mae\": val_mae}\n","    )\n","    print(\n","        f\"Epoch {epoch:02d} | Train MSE {train_loss:.4f} | Train MAE {train_mae:.4f} | \"\n","        f\"Val MSE {val_loss:.4f} | Val MAE {val_mae:.4f}\"\n","    )\n","\n","    if val_loss < best_loss:\n","        best_loss = val_loss\n","        patience_counter = 0\n","        torch.save(model.state_dict(), MODEL_PATH)\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= PATIENCE:\n","            print(\"Early stopping triggered.\")\n","            break"]},{"cell_type":"code","execution_count":23,"id":"aca2c12d","metadata":{"id":"aca2c12d","executionInfo":{"status":"ok","timestamp":1764930756445,"user_tz":-420,"elapsed":469,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"77c79d3e-0d8d-4cfc-bbd5-8b555f779b6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation MAE : 636.62\n","Validation RMSE: 844.91\n","Validation MAPE: 8.74%\n","Validation RMSPE: 12.55%\n","Validation sMAPE: 8.66%\n","Validation MASE: 0.46\n","Validation R2 : 0.9239\n"]}],"source":["import numpy as np\n","import torch\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score # Đảm bảo đã import r2_score\n","# ... các import khác (như MODEL_PATH, DEVICE, model, val_loader, target_scaler, df_train, TARGET_COL, split_date)\n","\n","if MODEL_PATH.exists():\n","    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n","model.eval()\n","\n","\n","def collect_predictions(loader):\n","    preds_list, targets_list = [], []\n","    with torch.no_grad():\n","        for features, targets in loader:\n","            features = features.to(DEVICE)\n","            preds = model(features).cpu().numpy()\n","            preds_list.append(preds)\n","            targets_list.append(targets.numpy())\n","    return np.concatenate(preds_list), np.concatenate(targets_list)\n","\n","\n","def calculate_mape(y_true, y_pred):\n","    mask = y_true != 0\n","    if not np.any(mask):\n","        return np.nan\n","    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n","\n","\n","def calculate_rmspe(y_true, y_pred):\n","    mask = y_true != 0\n","    if not np.any(mask):\n","        return np.nan\n","    return np.sqrt(np.mean(((y_true[mask] - y_pred[mask]) / y_true[mask]) ** 2)) * 100\n","\n","\n","def calculate_smape(y_true, y_pred):\n","    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n","    ratio = np.where(denominator == 0, 0, np.abs(y_pred - y_true) / denominator)\n","    return np.mean(ratio) * 100\n","\n","\n","def calculate_mase(y_true, y_pred, naive_errors):\n","    if naive_errors <= 0 or np.isnan(naive_errors):\n","        return np.nan\n","    return mean_absolute_error(y_true, y_pred) / naive_errors\n","\n","# Thêm hàm tính R2\n","def calculate_r2(y_true, y_pred):\n","    \"\"\"Tính hệ số xác định R-squared.\"\"\"\n","    return r2_score(y_true, y_pred)\n","\n","\n","val_preds_scaled, val_targets_scaled = collect_predictions(val_loader)\n","val_preds = target_scaler.inverse_transform(val_preds_scaled.reshape(-1, 1)).ravel()\n","val_targets = target_scaler.inverse_transform(val_targets_scaled.reshape(-1, 1)).ravel()\n","\n","mae = mean_absolute_error(val_targets, val_preds)\n","rmse = np.sqrt(mean_squared_error(val_targets, val_preds))\n","mape = calculate_mape(val_targets, val_preds)\n","rmspe = calculate_rmspe(val_targets, val_preds)\n","smape = calculate_smape(val_targets, val_preds)\n","\n","# Tính R2\n","r2 = calculate_r2(val_targets, val_preds)\n","\n","historical_train = df_train[df_train[\"Date\"] < split_date][TARGET_COL].values\n","if len(historical_train) > 1:\n","    naive_error = np.mean(np.abs(np.diff(historical_train)))\n","else:\n","    naive_error = np.nan\n","mase = calculate_mase(val_targets, val_preds, naive_error)\n","\n","print(f\"Validation MAE : {mae:,.2f}\")\n","print(f\"Validation RMSE: {rmse:,.2f}\")\n","print(f\"Validation MAPE: {mape:,.2f}%\")\n","print(f\"Validation RMSPE: {rmspe:,.2f}%\")\n","print(f\"Validation sMAPE: {smape:,.2f}%\")\n","print(f\"Validation MASE: {mase:,.2f}\")\n","print(f\"Validation R2 : {r2:,.4f}\")"]},{"cell_type":"code","execution_count":24,"id":"a62522dd","metadata":{"id":"a62522dd","executionInfo":{"status":"ok","timestamp":1764930762290,"user_tz":-420,"elapsed":5830,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f711a01-d531-4709-eece-a8acd4ee486b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test sequences built: (1113, 30, 30)\n","Saved 1113 predictions to /content/drive/MyDrive/ParquetFile/nbeats_predictions.csv\n"]}],"source":["def build_test_sequences(test_df: pd.DataFrame, history_df: pd.DataFrame, feature_cols: list, seq_len: int):\n","    sequences, store_ids, forecast_dates = [], [], []\n","    for _, row in test_df.iterrows():\n","        store_id = row[ID_COL]\n","        forecast_date = row[\"Date\"]\n","        end_date = forecast_date - pd.Timedelta(days=1)\n","\n","        store_history = history_df[\n","            (history_df[ID_COL] == store_id) & (history_df[\"Date\"] <= end_date)\n","        ].sort_values(\"Date\")\n","\n","        if len(store_history) < seq_len:\n","            continue\n","\n","        seq_features = store_history[feature_cols].tail(seq_len).to_numpy(dtype=np.float32)\n","        sequences.append(seq_features)\n","        store_ids.append(store_id)\n","        forecast_dates.append(forecast_date)\n","\n","    return np.array(sequences), store_ids, forecast_dates\n","\n","\n","scaled_history = df_train.copy()\n","scaled_history[FEATURE_COLS] = feature_scaler.transform(df_train[FEATURE_COLS])\n","scaled_history = scaled_history.sort_values([ID_COL, \"Date\"]).reset_index(drop=True)\n","\n","X_test_seq, test_store_ids, test_dates = build_test_sequences(test_scaled, scaled_history, FEATURE_COLS, SEQ_LEN)\n","print(f\"Test sequences built: {X_test_seq.shape}\")\n","\n","if len(X_test_seq) == 0:\n","    raise RuntimeError(\"No valid test sequences were created. Consider reducing SEQ_LEN or ensuring sufficient history.\")\n","\n","\n","test_ds = SequenceDataset(X_test_seq)\n","test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n","\n","model.eval()\n","test_preds_scaled = []\n","with torch.no_grad():\n","    for batch in test_loader:\n","        preds = model(batch.to(DEVICE)).cpu().numpy()\n","        test_preds_scaled.append(preds)\n","\n","flat_test_preds_scaled = np.concatenate(test_preds_scaled)\n","flat_test_preds = target_scaler.inverse_transform(flat_test_preds_scaled.reshape(-1, 1)).ravel()\n","\n","submission = pd.DataFrame({\n","    \"Store\": test_store_ids,\n","    \"Date\": test_dates,\n","    \"PredictedSales\": flat_test_preds,\n","})\n","\n","if \"Id\" in test_scaled.columns:\n","    id_lookup = test_scaled[[\"Store\", \"Date\", \"Id\"]].drop_duplicates()\n","    matched_ids = []\n","    for store, date in zip(test_store_ids, test_dates):\n","        match = id_lookup[(id_lookup[\"Store\"] == store) & (id_lookup[\"Date\"] == date)]\n","        matched_ids.append(match[\"Id\"].iloc[0] if not match.empty else np.nan)\n","    submission[\"Id\"] = matched_ids\n","    submission = submission[[\"Id\", \"Store\", \"Date\", \"PredictedSales\"]]\n","\n","output_path = RESULTS_DIR / \"nbeats_predictions.csv\"\n","submission.to_csv(output_path, index=False)\n","print(f\"Saved {len(submission)} predictions to {output_path}\")"]},{"cell_type":"code","source":[],"metadata":{"id":"zwmEUtWvFv8_"},"id":"zwmEUtWvFv8_","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3f277f26","executionInfo":{"status":"ok","timestamp":1764931152724,"user_tz":-420,"elapsed":207,"user":{"displayName":"Tiến Nguyễn","userId":"04037645608653952549"}},"outputId":"1d682a1c-5ae8-46ad-b646-b6243617ccc7"},"source":["torch.save(model.state_dict(), MODEL_PATH)\n","print(f\"Model saved to {MODEL_PATH}\")"],"id":"3f277f26","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved to /content/drive/MyDrive/ParquetFile/nbeats_best.pt\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}